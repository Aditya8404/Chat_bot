{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [39], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnltk\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/nltk/__init__.py:152\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mnltk\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtag\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[1;32m    151\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mnltk\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtokenize\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[0;32m--> 152\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mnltk\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtranslate\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[1;32m    153\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mnltk\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtree\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[1;32m    154\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mnltk\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msem\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/nltk/translate/__init__.py:24\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mnltk\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtranslate\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbleu_score\u001b[39;00m \u001b[39mimport\u001b[39;00m sentence_bleu \u001b[39mas\u001b[39;00m bleu\n\u001b[1;32m     23\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mnltk\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtranslate\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mribes_score\u001b[39;00m \u001b[39mimport\u001b[39;00m sentence_ribes \u001b[39mas\u001b[39;00m ribes\n\u001b[0;32m---> 24\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mnltk\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtranslate\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmeteor_score\u001b[39;00m \u001b[39mimport\u001b[39;00m meteor_score \u001b[39mas\u001b[39;00m meteor\n\u001b[1;32m     25\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mnltk\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtranslate\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m alignment_error_rate\n\u001b[1;32m     26\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mnltk\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtranslate\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mstack_decoder\u001b[39;00m \u001b[39mimport\u001b[39;00m StackDecoder\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/nltk/translate/meteor_score.py:13\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mitertools\u001b[39;00m \u001b[39mimport\u001b[39;00m chain, product\n\u001b[1;32m     11\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mimport\u001b[39;00m Callable, Iterable, List, Tuple\n\u001b[0;32m---> 13\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mnltk\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcorpus\u001b[39;00m \u001b[39mimport\u001b[39;00m WordNetCorpusReader, wordnet\n\u001b[1;32m     14\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mnltk\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mstem\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapi\u001b[39;00m \u001b[39mimport\u001b[39;00m StemmerI\n\u001b[1;32m     15\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mnltk\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mstem\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mporter\u001b[39;00m \u001b[39mimport\u001b[39;00m PorterStemmer\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/nltk/corpus/__init__.py:64\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[39mNLTK corpus readers.  The modules in this package provide functions\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[39mthat can be used to read corpus files in a variety of formats.  These\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     59\u001b[0m \n\u001b[1;32m     60\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     62\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mre\u001b[39;00m\n\u001b[0;32m---> 64\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mnltk\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcorpus\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mreader\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[1;32m     65\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mnltk\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcorpus\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutil\u001b[39;00m \u001b[39mimport\u001b[39;00m LazyCorpusLoader\n\u001b[1;32m     66\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mnltk\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtokenize\u001b[39;00m \u001b[39mimport\u001b[39;00m RegexpTokenizer\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/nltk/corpus/reader/__init__.py:57\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Natural Language Toolkit: Corpus Readers\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m# Copyright (C) 2001-2022 NLTK Project\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[39m# URL: <https://www.nltk.org/>\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[39m# For license information, see LICENSE.TXT\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[39mNLTK corpus readers.  The modules in this package provide functions\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[39mthat can be used to read corpus fileids in a variety of formats.  These\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[39misort:skip_file\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m---> 57\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mnltk\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcorpus\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mreader\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mplaintext\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[1;32m     58\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mnltk\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcorpus\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mreader\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutil\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[1;32m     59\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mnltk\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcorpus\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mreader\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapi\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/nltk/corpus/reader/plaintext.py:20\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mnltk\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcorpus\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mreader\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutil\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[1;32m     17\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mnltk\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtokenize\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[0;32m---> 20\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mPlaintextCorpusReader\u001b[39;00m(CorpusReader):\n\u001b[1;32m     21\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[39m    Reader for corpora that consist of plaintext documents.  Paragraphs\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[39m    are assumed to be split using blank lines.  Sentences and words can\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[39m    overriding the ``CorpusView`` class variable.\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m     32\u001b[0m     CorpusView \u001b[39m=\u001b[39m StreamBackedCorpusView\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/nltk/corpus/reader/plaintext.py:42\u001b[0m, in \u001b[0;36mPlaintextCorpusReader\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m CorpusView \u001b[39m=\u001b[39m StreamBackedCorpusView\n\u001b[1;32m     33\u001b[0m \u001b[39m\"\"\"The corpus view class used by this reader.  Subclasses of\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[39m   ``PlaintextCorpusReader`` may specify alternative corpus view\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[39m   classes (e.g., to skip the preface sections of documents.)\"\"\"\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\n\u001b[1;32m     38\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m     39\u001b[0m     root,\n\u001b[1;32m     40\u001b[0m     fileids,\n\u001b[1;32m     41\u001b[0m     word_tokenizer\u001b[39m=\u001b[39mWordPunctTokenizer(),\n\u001b[0;32m---> 42\u001b[0m     sent_tokenizer\u001b[39m=\u001b[39mnltk\u001b[39m.\u001b[39;49mdata\u001b[39m.\u001b[39mLazyLoader(\u001b[39m\"\u001b[39m\u001b[39mtokenizers/punkt/english.pickle\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m     43\u001b[0m     para_block_reader\u001b[39m=\u001b[39mread_blankline_block,\n\u001b[1;32m     44\u001b[0m     encoding\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mutf8\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     45\u001b[0m ):\n\u001b[1;32m     46\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[39m    Construct a new plaintext corpus reader for a set of documents\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \u001b[39m    located at the given root directory.  Example usage:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[39m        corpus into paragraph blocks.\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m     62\u001b[0m     CorpusReader\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, root, fileids, encoding)\n",
      "\u001b[0;31mAttributeError\u001b[0m: partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"
     ]
    }
   ],
   "source": [
    "import nltk\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('tensorflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bb182e37a17e9ab7984570196a1d6e9593833df194f7de5efc4cc218231042f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
